# preprocess, keep
# true positive: 0.6172839506172839, false negative: 0.19547325102880658, false positive: 0.18724279835390947

# don't preprocess, keep
# true positive: 0.565843621399177, false negative: 0.24279835390946503, false positive: 0.19135802469135801

# preprocess, keep [unknown change]
# true positive: 0.588477366255144, false negative: 0.2345679012345679, false positive: 0.17695473251028807


# preprocess, keep [unknown change]
# true positive: 0.588477366255144, false negative: 0.2345679012345679, false positive: 0.17695473251028807


# cleaned up, fixed preprocessing bug, one preprocessing method
# $ python -i extract_info.py --clear
# true positive: 0.533, false negative: 0.416, false positive: 0.0514

# only compare google if it gives an answer
# $ python -i extract_info.py --clear
# true positive: 0.533, false negative: 0.329, false positive: 0.138

# not sure what the change here is
# $ python -i extract_info.py --clear
# true positive: 0.591, false negative: 0.276, false positive: 0.134

# check max(clean, not clean) and every capitalized word
# true positive: 0.733, false negative: 0.105, false positive: 0.163

# don't check clean
# true positive: 0.726, false negative: 0.113, false positive: 0.16
# however, somewhat better performance for getting the correct name imo

# don't check clean but put spaces around -
# true positive: 0.728, false negative: 0.105, false positive: 0.167

# also remember to keep the dashses lol
# true positive: 0.77, false negative: 0.109, false positive: 0.121

# what if dashes but parsed correctly without fucking phone numbers
# true positive: 0.782, false negative: 0.0885, false positive: 0.13

# remove duplicate phone numbers
# true positive: 78.19%, false negative: 8.85%, false positive: 12.96%

# do things by hand? maybe some other change
# true positive: 82.51%, false negative: 4.53%, false positive: 12.96%

# add min and max contacts, give google more punctuation
# true positive: 83.54%, false negative: 4.53%, false positive: 11.93%

# send google only alpha words instead of words with alpha chars
# true positive: 83.54%, false negative: 4.53%, false positive: 11.93%


# a lot of errors are based on incorrectly identifying locations
# spacy might help a lot, actually, for forming consensus
# approches: examine every extra word to see if it's in google
# try different preprocessing to see where google gives max results

# cleaner data
# true positive: 84.57%, false negative: 4.53%, false positive: 10.91%

# refactored, maybe refine in all cases
# true positive: 86.63%, false negative: 4.53%, false positive: 8.85%

# use google to check every name seperately
# true positive: 87.04%, false negative: 4.53%, false positive: 8.44%

# actually always refine and trust google to say 'nothing'
# true positive: 85.39%, false negative: 6.79%, false positive: 7.82%
# welp

# don't trust google to say nothing
# true positive: 87.04%, false negative: 4.53%, false positive: 8.44%

# after some early refactoring that wasn't checked correctly
# correct: 86.83%, not enough: 4.53%, too many: 8.64%

# after tweaking refine,
# correct: 86.42%, not enough: 5.35%, too many: 8.23%

# after using the combinatorial refine
# correct: 87.85%, not enough 4.53%, too many: 7.61%

# after starting to use combinatorial extraction
# correct: 87.86%, not enough: 3.91%, too many: 8.23%

# fixing some bugs and imporoving performance, also max_names = sum(contact_counts)
# instead of max(contact_counts) -- not sure if merged
# correct: 88.48%, not enough: 4.53%, too many: 7.00%

# reloading the cache on the same?
# correct: 92.59%, not enough 4.53%, too many: 2.86%

# refactored statistics; corrected intersect, fiddled with combinatorials,
# added logging; tweaked nonlatin filtering; removed rechecking empty google
# correct: 91.56%, not enough 4.73%, too many: 3.70%
# took 384 seconds to run (an improvement over half an hour!)
# (subsequent runs with caching are ~10s!)

# tweaked cache, added loggers, pass extractors, reorganize tests
# add regex call stack testing
# correct: 91.56%, not enough: 4.73%, too many: 3.70%
# 1055 seconds to regenerate the entire cache
# 4.142 seconds with a complete cache
# could speed up significantly 1

# composed_functions are cached. 
# black formatting, extensive linting, type fiddling
# compose uses __wrapped__ instead of no_cache=True
# completely refactored regex test; strategies instead of methods
# refactored extract_info in min_max_contents
# all_capitalized_extract_names excludes all caps
correct: 90.95%, not enough: 5.35%, too many: 3.70% [retroactive]

# Refiners and Extractors are Lists
# Logger returns log [tests]
# fiddled with types for refiner generator
# added LABELED_CASES [tests]
# merge test cases, replaced "case" with "example" [tests]
# stages instead of steps, refactored regex_gen [tests]
# added reclassification [tests]
correct: 90.95%, not enough: 5.35%, too many: 3.70% [retroactive]
# refactored stages, removed soft_filter [MAIN]
correct: 90.95%, not enough: 9.05%, too many: 0.00% [retroactive]
# extensive linting [MAIN]
# refactored test_cases, refactored tests/tools, added tool_tests [tests, some main]
# fixed reclassify bug [tests]
# tweaked reporting [main], cleaned classification and added examples[tests]
# correct: 90.95%, not enough: 90.05%, too many: 0.00%

# logging locals into private, printing bug [tests]
# explicit remove_none instead of lambda, test tweaking
